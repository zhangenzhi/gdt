# Configuration for the AdaptiveFocusViT (GDT-ViT) Model

# A name for this specific experiment run, used for creating output directories
task_name: "gdt_vit_imagenet_v1"

# 1. Encoder (HierarchicalViTEncoder) Configuration
encoder:
  img_size:  256 # Input image size
  embed_dim: 768
  num_heads: 12
  in_channels: 3
  stages:
    - {depth: 4, patch_size_in: 32, patch_size_out: 16, k_selected_ratio: 0.25, max_seq_len: 64} # (256/32)^2 = 49
    - {depth: 4, patch_size_in: 16, patch_size_out: 8,  k_selected_ratio: 0.25, max_seq_len: 64}
    - {depth: 4, patch_size_in: 8,  patch_size_out: 4,  k_selected_ratio: 0.25, max_seq_len: 64}
    - {depth: 4, patch_size_in: 4,  patch_size_out: 2,  k_selected_ratio: 0.25, max_seq_len: 64}

# 2. Classifier (DownstreamViTClassifier) Configuration
classifier:
  target_leaf_size: 16
  embed_dim: 768 # Should generally match the encoder's output for simplicity
  depth: 6
  num_heads: 12
  num_classes: 1000

# 3. Training Hyperparameters
training:
  optimizer: "AdamW"
  learning_rate: 0.001
  weight_decay: 0.05
  scheduler: "CosineAnnealingLR"
  min_lr: 1.0e-6
  num_epochs: 100
  batch_size: 256
